// src/hooks/useMicStream.ts
import { useEffect, useRef } from "react";

export const useMicStream = (
  wsRef: React.MutableRefObject<WebSocket | null>
) => {
  const audioContextRef = useRef<AudioContext | null>(null);
  const mediaStreamRef = useRef<MediaStream | null>(null);
  const processorRef = useRef<ScriptProcessorNode | null>(null);
  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null);

  // ðŸŽ™ï¸ ë§ˆì´í¬ ê¶Œí•œ + ìž¡ìŒ ì œê±° ì˜µì…˜ ì ìš©
  const initMicPermission = async () => {
    if (!mediaStreamRef.current) {
      mediaStreamRef.current = await navigator.mediaDevices.getUserMedia({
        audio: {
          noiseSuppression: true,      // ðŸ”¥ í™˜ê²½ ì†ŒìŒ ì œê±°
          echoCancellation: true,      // ðŸ”¥ ë°˜í–¥ ì œê±°
          autoGainControl: true,       // ðŸ”¥ ìžë™ ìŒëŸ‰ ì¡°ì ˆ
          channelCount: 1
        }
      });
      console.log("ðŸŽ™ï¸ ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©ë¨ (ë…¸ì´ì¦ˆ ì œê±° ì ìš©ë¨)");
    }
  };

  // ðŸŽ§ ìŒì„± ìŠ¤íŠ¸ë¦¬ë° ì‹œìž‘
  const startStreaming = async () => {
    if (!wsRef.current || wsRef.current.readyState !== WebSocket.OPEN) {
      console.warn("âš ï¸ WebSocketì´ ì•„ì§ ì—´ë¦¬ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
      return;
    }

    await initMicPermission();

    const stream = mediaStreamRef.current!;
    console.log("ðŸŽ™ï¸ Audio streaming started");

    audioContextRef.current = new AudioContext({ sampleRate: 24000 });
    const audioCtx = audioContextRef.current;

    const source = audioCtx.createMediaStreamSource(stream);
    const processor = audioCtx.createScriptProcessor(4096, 1, 1);

    source.connect(processor);
    processor.connect(audioCtx.destination);

    processor.onaudioprocess = (e) => {
      if (!wsRef.current || wsRef.current.readyState !== WebSocket.OPEN) return;

      const input = e.inputBuffer.getChannelData(0); // Float32Array (24kHz)
      const pcm16 = floatTo16BitPCM(input);

      wsRef.current.send(pcm16);
    };

    processorRef.current = processor;
    sourceRef.current = source;
  };

  // ðŸ›‘ ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ
  const stopStreaming = () => {
    console.log("ðŸ›‘ Audio streaming stopped");

    processorRef.current?.disconnect();
    sourceRef.current?.disconnect();

    if (audioContextRef.current?.state !== "closed") {
      audioContextRef.current?.close();
    }

    mediaStreamRef.current?.getTracks().forEach((t) => t.stop());
    mediaStreamRef.current = null;
  };

  // ðŸ”‰ Float32Array â†’ 16bit PCM ë³€í™˜
  function floatTo16BitPCM(float32Array: Float32Array) {
    const buffer = new ArrayBuffer(float32Array.length * 2);
    const view = new DataView(buffer);

    let offset = 0;
    for (let i = 0; i < float32Array.length; i++, offset += 2) {
      const s = Math.max(-1, Math.min(1, float32Array[i]));
      view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);
    }

    return buffer;
  }

  // cleanup
  useEffect(() => {
    return () => {
      stopStreaming();
    };
  }, []);

  return { startStreaming, stopStreaming, initMicPermission };
};
